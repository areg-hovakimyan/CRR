{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('/Users/a1111/Desktop/group_project/CRR/db/Customer.csv')\n",
    "order_df = pd.read_csv('/Users/a1111/Desktop/group_project/CRR/db/Order.csv')\n",
    "product_df = pd.read_csv('/Users/a1111/Desktop/group_project/CRR/db/Product.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2022-04-10 00:00:00'), Timestamp('2024-03-31 00:00:00'))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preliminary data inspection to decide on the temporal split\n",
    "order_df['OrderDate'] = pd.to_datetime(order_df['OrderDate'])\n",
    "latest_order_date = order_df['OrderDate'].max()\n",
    "earliest_order_date = order_df['OrderDate'].min()\n",
    "\n",
    "(earliest_order_date, latest_order_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   CustomerID  TotalOrderCount  AverageOrderValue  DaysSinceLastOrder  \\\n",
       " 0           1              1.0        1544.520000               402.0   \n",
       " 1           2              2.0        1048.835000               161.0   \n",
       " 2           3              1.0        3538.560000               421.0   \n",
       " 3           4              1.0          85.640000               143.0   \n",
       " 4           5              3.0         969.436667               488.0   \n",
       " \n",
       "    ProductDiversity  Churn  \n",
       " 0               1.0   True  \n",
       " 1               2.0   True  \n",
       " 2               1.0   True  \n",
       " 3               1.0   True  \n",
       " 4               3.0   True  ,\n",
       " True     64\n",
       " False    36\n",
       " Name: Churn, dtype: int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the split date\n",
    "split_date = pd.to_datetime('2023-12-31')\n",
    "\n",
    "# Merging Order and Product on ProductID\n",
    "order_product_df = pd.merge(order_df, product_df, on='ProductID')\n",
    "\n",
    "# Calculating total order value for each order\n",
    "order_product_df['OrderValue'] = order_product_df['Quantity'] * order_product_df['Price']\n",
    "\n",
    "# Merging with Customer dataset on CustomerID \n",
    "full_df = pd.merge(order_product_df, customer_df, on='CustomerID')\n",
    "\n",
    "# Feature Engineering\n",
    "# Feature 1: Total Order Count by Customer (up to split_date for training set)\n",
    "total_order_count = full_df[full_df['OrderDate'] <= split_date].groupby('CustomerID')['OrderID'].nunique().reset_index(name='TotalOrderCount')\n",
    "\n",
    "# Feature 2: Average Order Value by Customer (up to split_date for training set)\n",
    "average_order_value = full_df[full_df['OrderDate'] <= split_date].groupby('CustomerID')['OrderValue'].mean().reset_index(name='AverageOrderValue')\n",
    "\n",
    "# Feature 3: Days Since Last Order (from split_date, as this feature is crucial for defining churn)\n",
    "# For the training set, we'll calculate days since the last order up to the split date\n",
    "full_df['DaysSinceLastOrder'] = (split_date - pd.to_datetime(full_df['OrderDate'])).dt.days\n",
    "days_since_last_order = full_df[full_df['OrderDate'] <= split_date].groupby('CustomerID')['DaysSinceLastOrder'].min().reset_index()\n",
    "\n",
    "# Feature 4: Product Diversity (Number of Unique Products Purchased)\n",
    "product_diversity = full_df[full_df['OrderDate'] <= split_date].groupby('CustomerID')['ProductID'].nunique().reset_index(name='ProductDiversity')\n",
    "\n",
    "# Merging all features into a single DataFrame for the training set\n",
    "features_df_train = customer_df[['CustomerID']].merge(total_order_count, on='CustomerID', how='left')\\\n",
    "                                                .merge(average_order_value, on='CustomerID', how='left')\\\n",
    "                                                .merge(days_since_last_order, on='CustomerID', how='left')\\\n",
    "                                                .merge(product_diversity, on='CustomerID', how='left')\n",
    "\n",
    "# Fill NaN values with 0 for customers who didn't place any order\n",
    "features_df_train.fillna(0, inplace=True)\n",
    "\n",
    "# Adjusting the churn definition for the training set\n",
    "# Let's consider customers as churned if they haven't made any order in the last 90 days up to the split date\n",
    "features_df_train['Churn'] = features_df_train['DaysSinceLastOrder'] > 90\n",
    "\n",
    "features_df_train.head(), features_df_train['Churn'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.99, 0.020000000000000018)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preparing the features and target variable for model training\n",
    "X_train = features_df_train[['TotalOrderCount', 'AverageOrderValue', 'DaysSinceLastOrder', 'ProductDiversity']]\n",
    "y_train = features_df_train['Churn']\n",
    "\n",
    "# Standardizing the features for the training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Logistic Regression model with L2 regularization\n",
    "model_lr = LogisticRegression(penalty='l2', C=1.0, random_state=42)\n",
    "\n",
    "# Cross-validation to evaluate model performance\n",
    "cv_scores = cross_val_score(model_lr, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "cv_scores.mean(), cv_scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing the Gradient Boosting Classifier\n",
    "model_gb = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Cross-validation to evaluate model performance\n",
    "cv_scores_gb = cross_val_score(model_gb, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "cv_scores_gb.mean(), cv_scores_gb.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a1111/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([25, 11, 16, 12, 36]),\n",
       "          CustomerID  TotalOrderCount  AverageOrderValue  DaysSinceLastOrder  \\\n",
       " Cluster                                                                       \n",
       " 0         46.880000         1.960000        1100.070467          341.360000   \n",
       " 1         48.909091         5.636364        1588.069883           79.636364   \n",
       " 2         59.312500         1.687500        2917.006042          291.062500   \n",
       " 3         58.833333         0.333333         189.311667           21.083333   \n",
       " 4         46.805556         3.416667        1352.027958           91.305556   \n",
       " \n",
       "          ProductDiversity     Churn  \n",
       " Cluster                              \n",
       " 0                1.920000  1.000000  \n",
       " 1                5.363636  0.363636  \n",
       " 2                1.625000  0.937500  \n",
       " 3                0.333333  0.083333  \n",
       " 4                3.250000  0.527778  )"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of clusters\n",
    "k = 5\n",
    "\n",
    "# Initializing K-Means with the chosen number of clusters and fitting it to the data\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "kmeans.fit(X_train_scaled)\n",
    "\n",
    "# Predicting the cluster labels for the dataset\n",
    "cluster_labels = kmeans.predict(X_train_scaled)\n",
    "\n",
    "# Adding the cluster labels to our features DataFrame\n",
    "features_df_train['Cluster'] = cluster_labels\n",
    "\n",
    "# Analyzing the distribution of customers across clusters\n",
    "cluster_distribution = np.bincount(cluster_labels)\n",
    "\n",
    "cluster_distribution, features_df_train.groupby('Cluster').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
